#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
csv_validator.py

This script reads a metadata CSV file and validates it against the formatting rules
defined by ICAEW. It checks for common formatting errors and provides
detailed feedback on issues found.

This validator is designed to work with CSV files generated by a_get_metadata.py
from the pypreservica scripts directory, which exports metadata and checksums from
Preservica assets and folders. The CSV format includes:

Required Headers:
- assetId: Unique asset identifier
- entity.entity_type: Type of entity (EntityType.ASSET or EntityType.FOLDER)
- asset.security_tag: Security classification (closed, open, public)
- icaew:ContentType: Content type from controlled vocabulary
- icaew:InternalReference: Internal reference in YYYYMMDD-Document-Name format
- icaew:Notes: Optional notes field
- entity.title: Title of the entity
- entity.description: Description of the entity
- dc:title: Dublin Core title
- dc:creator: Dublin Core creator
- dc:subject: Dublin Core subject
- dc:description: Dublin Core description
- dc:publisher: Dublin Core publisher
- dc:contributor: Dublin Core contributor
- dc:date: Dublin Core date (YYYY-MM-DD, YYYY-MM, or YYYY format)
- dc:type: Dublin Core type (from DCMI Type Vocabulary)
- dc:format: Dublin Core format (lowercase file extension)
- dc:identifier: Dublin Core identifier
- dc:source: Dublin Core source
- dc:language: Dublin Core language (ISO 639-1 code)
- dc:relation: Dublin Core relation
- dc:coverage: Dublin Core coverage
- dc:rights: Dublin Core rights

The validator ensures compliance with ICAEW metadata standards and formatting rules.
"""

import argparse
import csv
import re
import sys
from datetime import datetime
from typing import Dict, List, Tuple, Set
from pathlib import Path


class CSVValidator:
    def __init__(self, ignored_fields: Set[str] = None):
        """Initialize the validator with validation rules."""
        
        # Default ignored fields
        default_ignored = {'dc:source', 'dc:coverage', 'dc:rights', 'dc:contributor', 'dc:identifier'}
        if ignored_fields is not None:
            # User specified ignored fields
            if len(ignored_fields) == 0:
                # Empty set means include all fields (ignore none)
                self.ignored_fields = set()
            else:
                # User specified some fields to ignore, add to defaults
                self.ignored_fields = ignored_fields.union(default_ignored)
        else:
            # Use default ignored fields
            self.ignored_fields = default_ignored.copy()  # Make a copy to avoid modifying the original
        

        
        # Hardcoded acronyms for ICAEW content
        self.acronyms = {
            'OECD', 'IFRS', 'FRC', 'HMRC', 'UK', 'VAT', 'ICAEW', 'SME', 'SMEs',
            'PAYE', 'RTI', 'NIC', 'CGT', 'IHT', 'KPI', 'KPIs', 'UKEF',
            'AI', 'CBI', 'BBA', 'EEF', 'FLA', 'FSB', 'IOD', 'P2P',
            'BVCA', 'BDO', 'EY', 'KPMG', 'PwC', 'Deloitte', 'NESTA', 'RSA', 'MTD'
        }
        
        # Required headers that must be present in the CSV
        self.required_headers = [
            'assetId',
            'entity.entity_type',
            'asset.security_tag',
            'icaew:ContentType',
            'icaew:InternalReference',
            'icaew:Notes',
            'entity.title',
            'entity.description',
            'dc:title',
            'dc:creator',
            'dc:subject',
            'dc:description',
            'dc:publisher',
            'dc:contributor',
            'dc:date',
            'dc:type',
            'dc:format',
            'dc:identifier',
            'dc:source',
            'dc:language',
            'dc:relation',
            'dc:coverage',
            'dc:rights'
        ]
        
        # Controlled vocabulary for content types
        self.content_types = {
            'Annual report', 'Article', 'Committee papers', 'Database', 'eBook',
            'eBook chapter', 'eLearning module', 'Event', 'Form', 'Helpsheets and support',
            'Hub page', 'ICAEW consultation and response', 'Interview', 'Journal',
            'Learning material', 'Legal precedent', 'Library book', 'Listing',
            'Newsletter', 'No content type', 'Podcast', 'Press release',
            'Promotional material', 'Regional news', 'Regulations', 'Report',
            'Representation', 'Research guide', 'Speech or presentation', 'Synopsis',
            'Technical release', 'Thought leadership report', 'Webinar', 'Website'
        }
        
        # DCMI type values (sentence case) - Complete Dublin Core Type Vocabulary
        self.dcmi_types = {
            'Collection', 'Dataset', 'Event', 'Image', 'Interactive Resource', 
            'Moving Image', 'Physical Object', 'Service', 'Software', 'Sound', 'Text'
        }
        
        # Common ISO 639-1 language codes
        self.language_codes = {
            'en', 'ar', 'zh', 'fr', 'de', 'es', 'it', 'ja', 'ko', 'pt', 'ru', 'hi'
        }
        
        # Required fields (customizable)
        self.required_fields = [
            'assetId', 'entity.entity_type', 'asset.security_tag', 'icaew:ContentType', 
            'icaew:InternalReference', 'icaew:Notes', 'entity.title', 'entity.description',
            'dc:title', 'dc:creator', 'dc:subject', 'dc:description', 'dc:publisher',
            'dc:contributor', 'dc:date', 'dc:type', 'dc:format', 'dc:identifier',
            'dc:source', 'dc:language', 'dc:relation', 'dc:coverage', 'dc:rights'
        ]
        
        # Date format patterns
        self.date_patterns = [
            r'^\d{4}-\d{2}-\d{2}$',  # YYYY-MM-DD
            r'^\d{4}-\d{2}$',        # YYYY-MM
            r'^\d{4}$'               # YYYY
        ]
        
        # Internal reference pattern - allows unknown dates with 00 placeholders
        self.internal_ref_pattern = r'^\d{8}-[A-Za-z0-9-]+$'
        
        # Internal reference pattern for unknown dates
        self.internal_ref_pattern_with_unknown = r'^(\d{4})(\d{2})(\d{2})-[A-Za-z0-9-]+$'
        
        # Track field values by asset ID to check if ALL instances are empty
        self.asset_field_values = {}  # {asset_id: {field_name: [values]}}
        
        # Track which assets have already been reported for empty fields
        self.reported_empty_fields = set()  # {(asset_id, field_name)}
        
        # Initialize error tracking
        self.errors = []
        self.warnings = []
        self.stats = {
            'total_rows': 0,
            'rows_with_errors': 0,
            'rows_with_warnings': 0
        }



    def validate_headers(self, headers: List[str]) -> List[str]:
        """Validate that all required headers are present in the CSV."""
        issues = []
        missing_headers = []
        
        for required_header in self.required_headers:
            if required_header not in headers:
                missing_headers.append(required_header)
        
        if missing_headers:
            issues.append(f"Missing required headers: {', '.join(missing_headers)}")
        
        return issues

    def validate_title(self, title: str, row_num: int) -> List[str]:
        """Validate title formatting according to rules."""
        issues = []
        
        if not title:
            return issues
            
        # Check for acronym capitalization
        words = title.split()
        for word in words:
            # Remove punctuation for checking
            clean_word = re.sub(r'[^\w]', '', word)
            if clean_word.upper() in self.acronyms and clean_word != clean_word.upper():
                issues.append(f"Acronym '{clean_word}' should be in capitals: '{clean_word.upper()}'")
        
        # Check for sentence case (first word capitalized, rest lowercase except proper nouns)
        # Allow titles that start with numbers
        if title and not title[0].isupper() and not title[0].isdigit():
            issues.append("Title should start with a capital letter (sentence case)")
        
        # Check for proper colon usage (not em-dash or en-dash)
        if '—' in title or '–' in title:
            issues.append("Use colons (:) instead of em-dashes (—) or en-dashes (–) for title separators")
        
        # Check for proper date formatting in titles
        # Allow readable date formats (these are correct according to ICAEW guidance)
        readable_date_patterns = [
            r'\d{1,2}(?:st|nd|rd|th)\s+(?:January|February|March|April|May|June|July|August|September|October|November|December)\s+\d{4}',
            r'(?:January|February|March|April|May|June|July|August|September|October|November|December)\s+\d{1,2},?\s+\d{4}'
        ]
        
        # Check for non-readable date formats (these should be flagged)
        non_readable_date_patterns = [
            r'\d{4}-\d{2}-\d{2}'  # YYYY-MM-DD format in titles
        ]
        
        # Flag non-readable date formats
        for pattern in non_readable_date_patterns:
            if re.search(pattern, title):
                issues.append("Dates in titles should use readable format (e.g., '15th January 2024')")
                break
        
        return issues

    def validate_date(self, date_str: str, row_num: int) -> List[str]:
        """Validate date format."""
        issues = []
        
        if not date_str:
            return issues
            
        # Check if date matches expected patterns
        valid_format = False
        for pattern in self.date_patterns:
            if re.match(pattern, date_str):
                valid_format = True
                break
        
        if not valid_format:
            issues.append(f"Date '{date_str}' should be in YYYY-MM-DD, YYYY-MM, or YYYY format")
            return issues
        
        # Validate the actual date
        try:
            if len(date_str) == 10:  # YYYY-MM-DD
                datetime.strptime(date_str, '%Y-%m-%d')
            elif len(date_str) == 7:  # YYYY-MM
                datetime.strptime(date_str, '%Y-%m')
            elif len(date_str) == 4:  # YYYY
                int(date_str)  # Just check it's a valid integer
        except ValueError:
            issues.append(f"Invalid date format: '{date_str}'")
        
        return issues

    def validate_title_order(self, title: str, row_num: int) -> List[str]:
        """Validate title follows the order: title, subtitle, issue/volume, date."""
        issues = []
        
        if not title:
            return issues
            
        # Check for proper colon usage as separator
        if ':' in title:
            parts = title.split(':')
            if len(parts) >= 2:
                # Check if first letter after colon is capitalized (should not be)
                for i, part in enumerate(parts[1:], 1):
                    if part.strip() and part.strip()[0].isupper():
                        # Check if the capitalized word is an acronym
                        first_word = part.strip().split()[0]
                        clean_first_word = re.sub(r'[^\w]', '', first_word)
                        if clean_first_word.upper() not in self.acronyms:
                            issues.append("First letter after colon should not be capitalized")
                            break
        
        # Check for ampersand usage (should use "and")
        if '&' in title:
            issues.append("Use 'and' instead of '&' in titles")
        
        # Check for trailing periods
        if title.endswith('.'):
            issues.append("Title should not end with a period")
        
        return issues

    def validate_internal_reference(self, ref: str, row_num: int) -> List[str]:
        """Validate internal reference format."""
        issues = []
        
        if not ref:
            return issues
            
        # Check pattern with unknown date support
        match = re.match(self.internal_ref_pattern_with_unknown, ref)
        if not match:
            issues.append(f"Internal reference '{ref}' should follow YYYYMMDD-Document-Name format (use 00 for unknown dates)")
            return issues
        
        # Extract date parts
        year, month, day = match.groups()
        
        # Validate that unknown parts use 00
        if month == '00' and day != '00':
            issues.append("If month is unknown (00), day must also be unknown (00)")
        # Note: 0000 is valid for completely unknown dates according to ICAEW guidance
        
        # Check for invalid characters
        if '_' in ref or '.' in ref or ',' in ref or '&' in ref:
            issues.append("Internal reference should not contain underscores, periods, commas, or ampersands")
        
        # Check for proper acronym capitalization in reference
        parts = ref.split('-')
        if len(parts) >= 2:
            document_part = '-'.join(parts[1:])
            words = document_part.split('-')
            for word in words:
                if word.upper() in self.acronyms and word != word.upper():
                    issues.append(f"Acronym '{word}' in reference should be in capitals: '{word.upper()}'")
        
        # Validate title case for document name
        if len(parts) >= 2:
            document_part = '-'.join(parts[1:])
            words = document_part.split('-')
            for word in words:
                # Skip numeric words (likely date components) and empty words
                if word and not word.isdigit() and not word[0].isupper():
                    issues.append(f"icaew:InternalReference document name should use title case: '{word}' should be '{word.title()}'")
        
        return issues

    def validate_content_type(self, content_type: str, row_num: int) -> List[str]:
        """Validate content type against controlled vocabulary."""
        issues = []
        
        if not content_type:
            return issues
            
        if content_type not in self.content_types:
            issues.append(f"Content type '{content_type}' is not in the controlled vocabulary")
        
        return issues

    def validate_creator(self, creator: str, row_num: int) -> List[str]:
        """Validate creator field formatting."""
        issues = []
        
        if not creator:
            return issues
            
        # Check for proper ICAEW normalization
        if 'Institute of Chartered Accountants in England and Wales' in creator:
            issues.append("Use 'ICAEW' instead of 'Institute of Chartered Accountants in England and Wales'")
        
        # Check for proper semicolon separation
        if ';' in creator:
            creators = [c.strip() for c in creator.split(';')]
            if any(not c for c in creators):
                issues.append("Empty creator entries found in semicolon-separated list")
        
        # Check for trailing periods
        if creator.endswith('.'):
            issues.append("Field 'dc:creator' should not end with a period")
        
        return issues

    def validate_description(self, description: str, field_name: str, row_num: int) -> List[str]:
        """Validate description field."""
        issues = []
        
        if not description:
            return issues
            
        # Check for excessive whitespace
        if '  ' in description:
            issues.append(f"Field '{field_name}' contains excessive whitespace (multiple consecutive spaces)")
        
        # Check if description ends with period before AI description suffixes
        ai_suffixes = ['(AI-generated description)', '(AI generated description)']
        has_ai_suffix = False
        text_before_ai = description
        
        for suffix in ai_suffixes:
            if suffix in description:
                has_ai_suffix = True
                # Find the position of the AI suffix
                ai_pos = description.find(suffix)
                # Check if there's a period before the AI suffix
                text_before_ai = description[:ai_pos].strip()
                break
        
        if has_ai_suffix:
            if not text_before_ai.endswith('.'):
                issues.append(f"Field '{field_name}' should end with a period before AI description suffix")
        else:
            # If no AI suffix, check if it ends with a period or question mark
            if not (description.endswith('.') or description.endswith('?')):
                issues.append(f"Field '{field_name}' should end with a period or question mark")
        
        return issues

    def validate_type(self, type_value: str, row_num: int) -> List[str]:
        """Validate Type field against DCMI type values."""
        issues = []
        
        if not type_value:
            return issues
            
        if type_value not in self.dcmi_types:
            issues.append(f"Type '{type_value}' is not a valid DCMI type value")
        
        return issues

    def validate_language(self, language: str, row_num: int) -> List[str]:
        """Validate Language field against ISO 639-1 codes."""
        issues = []
        
        if not language:
            return issues
            
        if language not in self.language_codes:
            issues.append(f"Language code '{language}' is not a recognized ISO 639-1 code")
        
        return issues

    def validate_ascii_characters(self, text: str, field_name: str, row_num: int) -> List[str]:
        """Validate that text contains only ASCII characters."""
        issues = []
        
        if not text:
            return issues
            
        # Check for non-ASCII characters
        non_ascii_chars = []
        for char in text:
            if ord(char) > 127:
                non_ascii_chars.append(char)
        
        if non_ascii_chars:
            unique_chars = list(set(non_ascii_chars))
            issues.append(f"Field '{field_name}' contains non-ASCII characters: {unique_chars}")
        
        return issues

    def validate_whitespace_all(self, text: str, field_name: str, row_num: int) -> List[str]:
        """Validate that text has no leading/trailing whitespace or excessive whitespace."""
        issues = []
        
        if text is None:
            return issues
            
        # Check for leading/trailing whitespace
        if text != text.strip():
            issues.append(f"Field '{field_name}' has leading or trailing whitespace")
        
        # Check for excessive whitespace (multiple consecutive spaces)
        if '  ' in text:
            issues.append(f"Field '{field_name}' contains excessive whitespace (multiple consecutive spaces)")
        
        return issues

    def validate_required_fields(self, row: Dict[str, str], row_num: int) -> List[str]:
        """Validate that all required fields are not empty, tracking by asset ID."""
        issues = []
        asset_id = row.get('assetId', 'Unknown')
        
        # Check if ALL instances of each field are empty for this asset
        for field in self.required_fields:
            if field in self.ignored_fields:
                continue  # Skip ignored fields
            if asset_id in self.asset_field_values and field in self.asset_field_values[asset_id]:
                all_values = self.asset_field_values[asset_id][field]
                # Check if ALL values for this field are empty
                if all(not value or value.strip() == '' for value in all_values):
                    # Only report this error once per asset-field combination
                    if (asset_id, field) not in self.reported_empty_fields:
                        issues.append(f"Required field '{field}' is empty for all instances of asset {asset_id}")
                        self.reported_empty_fields.add((asset_id, field))
                else:
                    # If the field has content in any row, remove it from reported empty fields
                    # (in case it was previously reported as empty but now has content)
                    self.reported_empty_fields.discard((asset_id, field))
        
        return issues

    def validate_publisher(self, publisher: str, row_num: int) -> List[str]:
        """Validate publisher field."""
        issues = []
        
        if not publisher:
            return issues
            
        # Check for proper ICAEW normalization
        if 'Institute of Chartered Accountants in England and Wales' in publisher:
            issues.append("Use 'ICAEW' instead of 'Institute of Chartered Accountants in England and Wales'")
        
        # Check for trailing periods
        if publisher.endswith('.'):
            issues.append("Field 'dc:publisher' should not end with a period")
        
        return issues

    def validate_format(self, format_value: str, row_num: int) -> List[str]:
        """Validate format field - should be lowercase file extension."""
        issues = []
        
        if not format_value:
            return issues
            
        # Check if format is lowercase
        if format_value != format_value.lower():
            issues.append(f"Format should be lowercase: '{format_value.lower()}'")
        
        # Check for common file extensions
        valid_extensions = {
            'pdf', 'docx', 'doc', 'xlsx', 'xls', 'txt', 'srt', 'jpg', 'jpeg', 
            'png', 'tiff', 'tif', 'gif', 'bmp', 'mp4', 'avi', 'mov', 'mp3', 
            'wav', 'html', 'htm', 'xml', 'json', 'csv'
        }
        
        if format_value not in valid_extensions:
            issues.append(f"Format '{format_value}' may not be a standard file extension")
        
        return issues

    def validate_relation(self, relation: str, row_num: int) -> List[str]:
        """Validate relation field - should be parent folder or collection name."""
        issues = []
        
        if not relation:
            return issues
            
        # Check for proper semicolon separation if multiple relations
        if ';' in relation:
            relations = [r.strip() for r in relation.split(';')]
            if any(not r for r in relations):
                issues.append("Empty relation entries found in semicolon-separated list")
        
        return issues

    def validate_contributor(self, contributor: str, row_num: int) -> List[str]:
        """Validate contributor field formatting."""
        issues = []
        
        if not contributor:
            return issues
            
        # Check for proper semicolon separation
        if ';' in contributor:
            contributors = [c.strip() for c in contributor.split(';')]
            if any(not c for c in contributors):
                issues.append("Empty contributor entries found in semicolon-separated list")
        
        # Check for proper ICAEW normalization
        if 'Institute of Chartered Accountants in England and Wales' in contributor:
            issues.append("Use 'ICAEW' instead of 'Institute of Chartered Accountants in England and Wales'")
        
        # Check for trailing periods
        if contributor.endswith('.'):
            issues.append("Field 'dc:contributor' should not end with a period")
        
        return issues

    def validate_notes(self, notes: str, row_num: int) -> List[str]:
        """Validate icaew:Notes field."""
        issues = []
        
        # Notes field is optional, so empty is fine
        if not notes:
            return issues
            
        # Check for trailing periods
        if notes.endswith('.'):
            issues.append("Field 'icaew:Notes' should not end with a period")
        
        return issues

    def validate_security_tag(self, security_tag: str, row_num: int) -> List[str]:
        """Validate asset.security_tag field - must be 'closed', 'open', or 'public'."""
        issues = []
        
        if not security_tag:
            return issues
            
        valid_security_tags = {'closed', 'open', 'public'}
        
        if security_tag not in valid_security_tags:
            issues.append(f"asset.security_tag '{security_tag}' must be one of: {', '.join(sorted(valid_security_tags))}")
        
        return issues

    def get_error_emoji(self, error_message: str) -> str:
        """Return appropriate emoji for different types of error messages."""
        error_lower = error_message.lower()
        
        # Required field errors
        if "required field" in error_lower and "is empty" in error_lower:
            return "🔴"  # Red circle for missing required fields
        
        # Header validation errors
        if "missing required headers" in error_lower:
            return "📋"  # Clipboard for header issues
        
        # Title formatting errors
        if "title" in error_lower and ("should not end" in error_lower or "should start" in error_lower):
            return "📝"  # Memo for title issues
        
        # Period/formatting errors
        if "should not end with a period" in error_lower:
            return "⏸️"  # Pause button for period issues
        
        # Description errors
        if "description" in error_lower and ("should end" in error_lower or "contains excessive" in error_lower):
            return "📄"  # Document for description issues
        
        # Date/format errors
        if "date" in error_lower or "format" in error_lower:
            return "📅"  # Calendar for date/format issues
        
        # Internal reference errors
        if "internal reference" in error_lower:
            return "🔗"  # Link for reference issues
        
        # Content type/type errors
        if "content type" in error_lower or "type" in error_lower and "not in" in error_lower:
            return "🏷️"  # Label for type issues
        
        # Language errors
        if "language" in error_lower:
            return "🌐"  # Globe for language issues
        
        # Security tag errors
        if "security_tag" in error_lower:
            return "🔒"  # Lock for security issues
        
        # Whitespace/formatting errors
        if "whitespace" in error_lower or "leading" in error_lower or "trailing" in error_lower:
            return "🧹"  # Broom for whitespace issues
        
        # ASCII character errors
        if "ascii" in error_lower or "non-ascii" in error_lower:
            return "🔤"  # Alphabet for character issues
        
        # Copy/consistency errors
        if "should be an exact copy" in error_lower:
            return "🔄"  # Arrows for copy issues
        
        # Default error emoji
        return "❌"

    def get_warning_emoji(self, warning_message: str) -> str:
        """Return appropriate emoji for different types of warning messages."""
        warning_lower = warning_message.lower()
        
        # Period warnings
        if "should not end with a period" in warning_lower:
            return "⏸️"  # Pause button for period issues
        
        # Whitespace warnings
        if "whitespace" in warning_lower or "leading" in warning_lower or "trailing" in warning_lower:
            return "🧹"  # Broom for whitespace issues
        
        # Format warnings
        if "format" in warning_lower and "should be" in warning_lower:
            return "📅"  # Calendar for format issues
        
        # Separation warnings
        if "semicolon" in warning_lower or "separation" in warning_lower:
            return "🔗"  # Link for separation issues
        
        # Default warning emoji
        return "⚠️"

    def validate_row(self, row: Dict[str, str], row_num: int) -> Tuple[List[str], List[str]]:
        """Validate a single row of data."""
        errors = []
        warnings = []
        
        # Validate required fields first
        required_issues = self.validate_required_fields(row, row_num)
        errors.extend(required_issues)
        
        # Validate title formatting
        if 'dc:title' not in self.ignored_fields:
            title_issues = self.validate_title(row.get('dc:title', ''), row_num)
            errors.extend(title_issues)
            
            # Validate title order and formatting
            title_order_issues = self.validate_title_order(row.get('dc:title', ''), row_num)
            errors.extend(title_order_issues)
        
        # Validate entity.title (should match dc:title)
        if 'entity.title' not in self.ignored_fields and 'dc:title' not in self.ignored_fields:
            entity_title = row.get('entity.title', '')
            dc_title = row.get('dc:title', '')
            if entity_title != dc_title:
                errors.append(f"entity.title should be an exact copy of dc:title")
        
        # entity.title uses same formatting rules as dc:title, so no need to validate separately
        
        # Validate date
        if 'dc:date' not in self.ignored_fields:
            date_issues = self.validate_date(row.get('dc:date', ''), row_num)
            errors.extend(date_issues)
        
        # Validate internal reference
        if 'icaew:InternalReference' not in self.ignored_fields:
            ref_issues = self.validate_internal_reference(row.get('icaew:InternalReference', ''), row_num)
            errors.extend(ref_issues)
        
        # Validate content type
        if 'icaew:ContentType' not in self.ignored_fields:
            content_issues = self.validate_content_type(row.get('icaew:ContentType', ''), row_num)
            errors.extend(content_issues)
        
        # Validate type
        if 'dc:type' not in self.ignored_fields:
            type_issues = self.validate_type(row.get('dc:type', ''), row_num)
            errors.extend(type_issues)
        
        # Validate language
        if 'dc:language' not in self.ignored_fields:
            language_issues = self.validate_language(row.get('dc:language', ''), row_num)
            errors.extend(language_issues)
        
        # Validate format
        if 'dc:format' not in self.ignored_fields:
            format_issues = self.validate_format(row.get('dc:format', ''), row_num)
            errors.extend(format_issues)
        
        # Validate publisher
        if 'dc:publisher' not in self.ignored_fields:
            publisher_issues = self.validate_publisher(row.get('dc:publisher', ''), row_num)
            warnings.extend(publisher_issues)  # Publisher issues are warnings
        
        # Validate contributor
        if 'dc:contributor' not in self.ignored_fields:
            contributor_issues = self.validate_contributor(row.get('dc:contributor', ''), row_num)
            warnings.extend(contributor_issues)  # Contributor issues are warnings
        
        # Validate relation
        if 'dc:relation' not in self.ignored_fields:
            relation_issues = self.validate_relation(row.get('dc:relation', ''), row_num)
            warnings.extend(relation_issues)  # Relation issues are warnings
        
        # Validate creator
        if 'dc:creator' not in self.ignored_fields:
            creator_issues = self.validate_creator(row.get('dc:creator', ''), row_num)
            warnings.extend(creator_issues)  # Creator issues are warnings
        
        # Validate descriptions (both entity.description and dc:description use same rules)
        for desc_field in ['entity.description', 'dc:description']:
            if desc_field not in self.ignored_fields:
                desc_value = row.get(desc_field, '')
                if desc_value:  # Only validate if field has content
                    desc_issues = self.validate_description(desc_value, desc_field, row_num)
                    warnings.extend(desc_issues)  # Description issues are warnings
        
        # Validate notes
        if 'icaew:Notes' not in self.ignored_fields:
            notes_issues = self.validate_notes(row.get('icaew:Notes', ''), row_num)
            warnings.extend(notes_issues)  # Notes issues are warnings
        
        # Validate security tag
        if 'asset.security_tag' not in self.ignored_fields:
            security_tag_issues = self.validate_security_tag(row.get('asset.security_tag', ''), row_num)
            warnings.extend(security_tag_issues) # Security tag issues are warnings
        
        # Validate ASCII characters for all text fields
        text_fields_to_check = ['dc:title', 'dc:creator', 'dc:description', 'entity.title', 'entity.description', 'dc:publisher', 'dc:contributor', 'dc:relation']
        for field in text_fields_to_check:
            if field not in self.ignored_fields:
                value = row.get(field, '')
                if value:  # Only validate if field has content
                    ascii_issues = self.validate_ascii_characters(value, field, row_num)
                    errors.extend(ascii_issues)
        
        # Validate whitespace for all fields
        for field, value in row.items():
            if field not in self.ignored_fields:
                whitespace_issues = self.validate_whitespace_all(value, field, row_num)
                warnings.extend(whitespace_issues)  # Whitespace issues are warnings
            
        return errors, warnings

    def validate_csv(self, csv_file: str) -> None:
        """Validate the entire CSV file."""
        print(f"Validating CSV file: {csv_file}")
        print("=" * 60)
        
        try:
            with open(csv_file, 'r', encoding='utf-8') as file:
                # Read the raw CSV data to handle duplicate columns properly
                csv_data = list(csv.reader(file))
                if not csv_data:
                    print("Error: CSV file is empty.")
                    sys.exit(1)
                
                headers = csv_data[0]
                

                
                # Validate headers first
                header_issues = self.validate_headers(headers)
                if header_issues:
                    print("\nHEADER VALIDATION ISSUES:")
                    for issue in header_issues:
                        print(f"  {self.get_error_emoji(issue)} {issue}")
                        self.errors.append((0, issue))  # Row 0 for header issues
                
                # Create a mapping from field name to all column indices (handle duplicates)
                field_to_columns = {}
                for i, header in enumerate(headers):
                    if header not in field_to_columns:
                        field_to_columns[header] = []
                    field_to_columns[header].append(i)
                
                # First pass: collect all field values by asset ID
                rows = []
                for row_num, row_data in enumerate(csv_data[1:], start=2):  # Start at 2 because row 1 is header
                    self.stats['total_rows'] += 1
                    
                    # Convert row data to dict using our field mapping (handle duplicates by combining values)
                    row = {}
                    for field_name, col_indices in field_to_columns.items():
                        values = []
                        for col_index in col_indices:
                            if col_index < len(row_data):
                                value = row_data[col_index].strip()
                                if value:  # Only add non-empty values
                                    values.append(value)
                        # Join multiple values with semicolon, or use first value if only one
                        if values:
                            row[field_name] = '; '.join(values) if len(values) > 1 else values[0]
                        else:
                            row[field_name] = ''
                    
                    rows.append((row_num, row))
                    
                    # Track field values for this asset
                    asset_id = row.get('assetId', 'Unknown')
                    if asset_id not in self.asset_field_values:
                        self.asset_field_values[asset_id] = {}
                    
                    for field in self.required_fields:
                        if field in self.ignored_fields:
                            continue
                        value = row.get(field, '')
                        if field not in self.asset_field_values[asset_id]:
                            self.asset_field_values[asset_id][field] = []
                        self.asset_field_values[asset_id][field].append(value)
                        

                

                
                # Second pass: validate each row with complete asset information
                for row_num, row in rows:
                    errors, warnings = self.validate_row(row, row_num)
                    
                    # Get assetId for context
                    asset_id = row.get('assetId', 'Unknown')
                    
                    if errors:
                        self.stats['rows_with_errors'] += 1
                        print(f"\nRow {row_num} - ERRORS:")
                        print(f"  📁 Asset ID: {asset_id}")
                        for error in errors:
                            print(f"  {self.get_error_emoji(error)} {error}")
                            self.errors.append((row_num, error))
                    
                    if warnings:
                        self.stats['rows_with_warnings'] += 1
                        print(f"\nRow {row_num} - WARNINGS:")
                        print(f"  📁 Asset ID: {asset_id}")
                        for warning in warnings:
                            print(f"  {self.get_warning_emoji(warning)} {warning}")
                            self.warnings.append((row_num, warning))
                
        except FileNotFoundError:
            print(f"Error: File '{csv_file}' not found.")
            sys.exit(1)
        except Exception as e:
            print(f"Error reading CSV file: {e}")
            sys.exit(1)

    def print_summary(self) -> None:
        """Print a summary of validation results."""
        print("\n" + "=" * 60)
        print("VALIDATION SUMMARY")
        print("=" * 60)
        
        print(f"Total rows processed: {self.stats['total_rows']}")
        print(f"Rows with errors: {self.stats['rows_with_errors']}")
        print(f"Rows with warnings: {self.stats['rows_with_warnings']}")
        print(f"Total errors found: {len(self.errors)}")
        print(f"Total warnings found: {len(self.warnings)}")
        
        if self.errors:
            print(f"\nERROR SUMMARY:")
            error_types = {}
            for _, error in self.errors:
                error_type = error.split(':')[0] if ':' in error else 'Other'
                error_types[error_type] = error_types.get(error_type, 0) + 1
            
            for error_type, count in sorted(error_types.items()):
                print(f"  {error_type}: {count}")
        
        if self.warnings:
            print(f"\nWARNING SUMMARY:")
            warning_types = {}
            for _, warning in self.warnings:
                warning_type = warning.split(':')[0] if ':' in warning else 'Other'
                warning_types[warning_type] = warning_types.get(warning_type, 0) + 1
            
            for warning_type, count in sorted(warning_types.items()):
                print(f"  {warning_type}: {count}")


def main():
    """Main function to run the CSV validator."""
    parser = argparse.ArgumentParser(
        description='Validate CSV metadata files against ICAEW formatting rules.',
        epilog="""
Default ignored fields: dc:source, dc:coverage, dc:rights, dc:contributor, dc:identifier

To include these fields in validation, use the --ignore_fields option with an empty string or 
explicitly list only the fields you want to ignore. For example:
  --ignore_fields=""  # Include all fields in validation
  --ignore_fields="dc:source,dc:coverage"  # Only ignore these two fields
        """
    )
    parser.add_argument('csv_file', help='Path to the CSV file to validate')
    parser.add_argument('--ignore_fields', 
                       help='Comma-separated list of fields to ignore during validation. '
                            'By default, dc:source, dc:coverage, dc:rights, dc:contributor, '
                            'and dc:identifier are ignored. Use empty string to include all fields.')
    
    args = parser.parse_args()
    
    if not Path(args.csv_file).exists():
        print(f"Error: File '{args.csv_file}' not found.")
        sys.exit(1)
    
    # Parse ignored fields
    ignored_fields = set()
    if args.ignore_fields is not None:  # Allow empty string to mean "include all fields"
        if args.ignore_fields.strip() == "":
            # Empty string means include all fields (ignore none)
            ignored_fields = set()
        else:
            ignored_fields = {field.strip() for field in args.ignore_fields.split(',')}
        print(f"Ignoring fields: {', '.join(sorted(ignored_fields)) if ignored_fields else 'none'}")
    else:
        # No --ignore_fields argument provided, use defaults
        print("Using default ignored fields: dc:source, dc:coverage, dc:rights, dc:contributor, dc:identifier")
        ignored_fields = None  # This will trigger the default behavior in CSVValidator
    
    validator = CSVValidator(ignored_fields=ignored_fields)
    validator.validate_csv(args.csv_file)
    validator.print_summary()


if __name__ == "__main__":
    main() 